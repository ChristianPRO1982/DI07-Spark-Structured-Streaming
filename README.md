# Analyse de flux de donnÃ©es en temps rÃ©el avec Spark Structured Streaming

# Veille

## DÃ©finitions

### on-premise

* `on-premise = oÃ¹ Ã§a tourne`
* `on-promise â‰  cloud`

> ğŸ‘‰ on-premise = oÃ¹ Ã§a tourne, et qui gÃ¨re lâ€™infrastructure (hardware, rÃ©seau, sÃ©curitÃ©, dÃ©ploiement).

### Apache Spark

* `Spark = moteur distribuÃ© batch + streaming`
>Pandas-like API + SQL + exÃ©cution distribuÃ©e + streaming + tolÃ©rance aux pannes

*lâ€™API nâ€™est quâ€™une faÃ§ade dâ€™un moteur distribuÃ©.*

### Apache Kafka

* `Kafka = log dâ€™Ã©vÃ©nements + dÃ©couplage + relecture`
* `Kafka â‰  queue / trigger`
> une couche de streaming qui collecte/stocke/rejoue des Ã©vÃ©nements, et permet Ã  Spark (ou dâ€™autres) de consommer en continu, de faÃ§on scalable et fiable

## Quel problÃ¨me Kafka rÃ©sout que Spark seul ne rÃ©sout pas bien ?

> Kafka apporte une couche de dÃ©couplage et de persistance des flux qui permet Ã  Spark de traiter des donnÃ©es en continu de maniÃ¨re fiable, scalable et tolÃ©rante aux pannes, en absorbant les pics de charge et en permettant la reprise du traitement Ã  partir dâ€™un offset prÃ©cis.

> **Kafka garantit la disponibilitÃ© des Ã©vÃ©nements, Spark garantit la cohÃ©rence du traitement.**

### dÃ©veloppement

> Kafka permet de collecter et stocker des donnÃ©es brutes sous forme dâ€™Ã©vÃ©nements, sans transformation mÃ©tier, en assurant leur persistance via des offsets.

> Il dÃ©couple les producteurs (capteurs IoT) des consommateurs (Spark), ce qui permet Ã  Spark de consommer les donnÃ©es Ã  son propre rythme, dâ€™absorber des pics de charge, et de reprendre le traitement Ã  partir dâ€™un offset prÃ©cis en cas dâ€™erreur ou de redÃ©marrage.

**En substance :**
* Kafka absorbe le flux brut
* Spark traite quand il peut, Ã  son rythme
* Et surtout : on peut reprendre

**Exemples :**
* pics IoT â†’ buffer Kafka (`anti-indigestion` ğŸ‘)
* bug applicatif â†’ reprise Ã  offset N (`Ã§a, câ€™est du vÃ©cu`, *et le jury adore*)

**Concepts :**
* Kafka ne fait pas de transformation mÃ©tier, mais il fait bien :
  * de la distribution (partitions),
  * de la rÃ©plication (tolÃ©rance aux pannes).
  * `â†’ Ce nâ€™est pas Spark, mais ce nâ€™est pas â€œjuste du stockageâ€.`
* Spark ne â€œ*cible*â€ pas manuellement les offsets en pratique :
  * il les gÃ¨re automatiquement via les consumer groups + checkpoints,
  * mais ton raisonnement reste correct conceptuellement.

## Workflow

**capteurs â†’ Kafka â†’ Spark**