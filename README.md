# Analyse de flux de donnÃ©es en temps rÃ©el avec Spark Structured Streaming

# Apache Kafka / Apache Spark

## DÃ©finitions

### on-premise

* `on-premise = oÃ¹ Ã§a tourne`
* `on-premise â‰  cloud`

> ğŸ‘‰ on-premise = oÃ¹ Ã§a tourne, et qui gÃ¨re lâ€™infrastructure (hardware, rÃ©seau, sÃ©curitÃ©, dÃ©ploiement).

### Apache Kafka

* `Kafka = log dâ€™Ã©vÃ©nements + dÃ©couplage + relecture`
* `Kafka â‰  queue / trigger`
> une couche de streaming qui collecte/stocke/rejoue des Ã©vÃ©nements, et permet Ã  Spark (ou dâ€™autres) de consommer en continu, de faÃ§on scalable et fiable

### Apache Spark

* `Spark = moteur distribuÃ© batch + streaming`
> Pandas-like API + SQL + exÃ©cution distribuÃ©e + streaming + tolÃ©rance aux pannes

*lâ€™API nâ€™est quâ€™une faÃ§ade dâ€™un moteur distribuÃ©.*

## A retenir

> Spark Structured Streaming fournit une API temps rÃ©el basÃ©e sur un modÃ¨le micro-batch, garantissant cohÃ©rence et tolÃ©rance aux pannes.

> Kafka organise les donnÃ©es par topics dÃ©coupÃ©s en partitions, dans lesquelles les messages sont identifiÃ©s par des offsets, tandis que Spark consomme ces offsets via un consumer group en assurant la reprise grÃ¢ce aux checkpoints.

## Quel problÃ¨me Kafka rÃ©sout que Spark seul ne rÃ©sout pas bien ?

> Kafka apporte une couche de dÃ©couplage et de persistance des flux qui permet Ã  Spark de traiter des donnÃ©es en continu de maniÃ¨re fiable, scalable et tolÃ©rante aux pannes, en absorbant les pics de charge et en permettant la reprise du traitement Ã  partir dâ€™un offset prÃ©cis.

> **Kafka garantit la disponibilitÃ© des Ã©vÃ©nements, Spark garantit la cohÃ©rence du traitement.**

### dÃ©veloppement

> Kafka permet de collecter et stocker des donnÃ©es brutes sous forme dâ€™Ã©vÃ©nements, sans transformation mÃ©tier, en assurant leur persistance via des offsets.

âš ï¸ *Techniquement, Kafka peut faire un minimum de transformation (Kafka Streams, SMT).*

> Il dÃ©couple les producteurs (capteurs IoT) des consommateurs (Spark), ce qui permet Ã  Spark de consommer les donnÃ©es Ã  son propre rythme, dâ€™absorber des pics de charge, et de reprendre le traitement Ã  partir dâ€™un offset prÃ©cis en cas dâ€™erreur ou de redÃ©marrage.

**En substance :**
* Kafka absorbe le flux brut
* Spark traite quand il peut, Ã  son rythme
* Et surtout : on peut reprendre

**Exemples :**
* pics IoT â†’ buffer Kafka (`anti-indigestion` ğŸ‘)
* bug applicatif â†’ reprise Ã  offset N (`Ã§a, câ€™est du vÃ©cu`)

**Concepts :**
* Kafka ne fait pas de transformation mÃ©tier, mais il fait bien :
  * de la distribution (partitions),
  * de la rÃ©plication (tolÃ©rance aux pannes).
  * `â†’ Ce nâ€™est pas Spark, mais ce nâ€™est pas â€œjuste du stockageâ€.`
* Spark ne â€œ*cible*â€ pas manuellement les offsets en pratique :
  * il les gÃ¨re automatiquement via les consumer groups + checkpoints,
  * mais ton raisonnement reste correct conceptuellement.

# Workflow

**capteurs â†’ Kafka â†’ Spark**

# Vocabulaire clÃ© (Kafka / Spark Streaming)
## Endpoint
> ğŸ‘‰ Un endpoint est un point dâ€™accÃ¨s rÃ©seau Ã  un service.

Dans le contexte du brief :
* Kafka : host:port dâ€™un broker (localhost:9092)
* Spark : endpoint Kafka pour lire/Ã©crire des messages
* API : URL exposÃ©e par un service

> ğŸ‘‰ **Ã€ retenir :**
Un endpoint ne fait rien tout seul : câ€™est lâ€™adresse oÃ¹ un service est joignable.

## Partition (Kafka)
> ğŸ‘‰ Une partition est une sous-partie ordonnÃ©e dâ€™un topic Kafka.
* Un topic est dÃ©coupÃ© en N partitions
* Chaque partition est :
  * ordonnÃ©e (ordre garanti dans la partition),
  * append-only (on ajoute Ã  la fin),
  * indÃ©pendante des autres partitions

**Pourquoi les partitions existent :**
* parallÃ©lisme (plusieurs consumers en mÃªme temps),
* montÃ©e en charge,
* rÃ©partition des donnÃ©es.

> ğŸ‘‰ **RÃ¨gle clÃ© :**
Lâ€™ordre nâ€™est garanti que dans une partition, jamais entre partitions.

## Offset (Kafka)

> ğŸ‘‰ Un offset est un index numÃ©rique qui identifie la position dâ€™un message dans une partition.

**Ce quâ€™est un offset :**
* un entier croissant (0, 1, 2, 3, â€¦)
* unique par partition
* attribuÃ© automatiquement par Kafka
* liÃ© Ã  un message prÃ©cis

**Ce quâ€™il nâ€™est pas :**
* âŒ pas un timestamp
* âŒ pas global au topic
* âŒ pas une clÃ© mÃ©tier

**Organisation rÃ©elle :**
```
Topic
 â”œâ”€ Partition 0 : offset 0 â†’ 1 â†’ 2 â†’ 3
 â”œâ”€ Partition 1 : offset 0 â†’ 1 â†’ 2
 â””â”€ Partition 2 : offset 0 â†’ 1
```

Chaque partition **a sa propre suite dâ€™offsets**.

**Taille dâ€™un offset :**
* conceptuellement : un nombre (int64)
* physiquement : stockÃ© avec le message dans le log Kafka
* ce nâ€™est pas le message, juste son index

## Consumer Group

> ğŸ‘‰ Un consumer group est un groupe logique de consommateurs qui se partagent les partitions dâ€™un topic.

* 1 partition â†’ 1 consumer max dans un group
* permet :
  * scalabilitÃ©,
  * tolÃ©rance aux pannes,
  * reprise automatique

Spark Structured Streaming **= un consumer group Kafka**.

## Commit dâ€™offset

> ğŸ‘‰ Committer un offset = dire â€œjâ€™ai traitÃ© jusquâ€™iciâ€.

* Kafka stocke les offsets consommÃ©s
* Spark dÃ©cide quand committer :
  * aprÃ¨s Ã©criture rÃ©ussie (Delta, sink, etc.)
  * via checkpoint

> ğŸ‘‰ Si Spark plante avant commit â†’ les messages sont relus.

## Endpoint Kafka vs Topic

Petit piÃ¨ge classique :

* Endpoint = oÃ¹ se connecter (localhost:9092)
* Topic = quoi lire/Ã©crire (iot_sensor_data)

## Mini-schÃ©ma mental (Ã  garder en tÃªte)
```
Capteur
  â†“
Kafka endpoint (broker)
  â†“
Topic
  â†“
Partitions
  â†“
Offsets
  â†“
Spark (consumer group + checkpoint)
```

# Concurrence

## ğŸ”„ Outils de streaming / traitement de flux
> (Concurrents de Spark Structured Streaming)

| Outil                                 | Type                  | Points forts                      | DiffÃ©rence clÃ© avec Spark |
| ------------------------------------- | --------------------- | --------------------------------- | ------------------------- |
| **Apache Spark Structured Streaming** | Micro-batch streaming | Robuste, SQL, batch + streaming   | Latence > Flink           |
| **Apache Flink**                      | Streaming natif       | Vrai streaming, event-time avancÃ© | Plus complexe Ã  opÃ©rer    |
| **Apache Beam**                       | SDK unifiÃ©            | PortabilitÃ© multi-engines         | Pas un moteur             |
| **Kafka Streams**                     | Lib Java              | LÃ©ger, intÃ©grÃ© Kafka              | Pas distribuÃ© seul        |
| **ksqlDB**                            | Streaming SQL         | SQL temps rÃ©el                    | Cas dâ€™usage limitÃ©s       |
| **Apache Storm**                      | Streaming bas niveau  | TrÃ¨s faible latence               | Ancien, verbeux           |
| **Serverless streaming**              | Event-driven          | ScalabilitÃ© auto                  | DÃ©pendance cloud          |

## ğŸ“¨ Message brokers / Pub-Sub
> (Concurrents de Kafka)

| Outil                | Type              | Points forts                 | DiffÃ©rence clÃ© avec Kafka    |
| -------------------- | ----------------- | ---------------------------- | ---------------------------- |
| **Apache Kafka**     | Log distribuÃ©     | Replay, dÃ©bit massif         | ComplexitÃ© infra             |
| **Apache Pulsar**    | Pub-Sub distribuÃ© | Multi-tenant, storage sÃ©parÃ© | Moins rÃ©pandu                |
| **RabbitMQ**         | Message Queue     | Routing avancÃ©               | Pas conÃ§u pour replay massif |
| **AWS Kinesis**      | Streaming managÃ©  | IntÃ©grÃ© AWS                  | Cloud only                   |
| **Google Pub/Sub**   | Pub-Sub managÃ©    | ScalabilitÃ© auto             | Pas dâ€™on-prem                |
| **Azure Event Hubs** | Event streaming   | Ã‰quivalent Kafka Azure       | Azure only                   |
| **Redis Streams**    | Streams mÃ©moire   | Faible latence               | RÃ©tention limitÃ©e            |

## ğŸ“¦ Ingestion / orchestration / pipelines
> (ComplÃ©ment au streaming)

| Outil              | RÃ´le                  | Usage principal  |
| ------------------ | --------------------- | ---------------- |
| **Apache NiFi**    | Ingestion visuelle    | Routage de flux  |
| **Apache Airflow** | Orchestration batch   | ETL planifiÃ©s    |
| **Prefect**        | Orchestration moderne | Pipelines Python |
| **Dagster**        | Data orchestration    | Data-centric     |
| **dbt**            | Transformation SQL    | ELT analytique   |

## ğŸ“Š Analytique temps rÃ©el / stockage
> (Consommateurs de flux)

| Outil             | Type               | Usage                |
| ----------------- | ------------------ | -------------------- |
| **ClickHouse**    | OLAP               | Analytique rapide    |
| **Apache Druid**  | OLAP temps rÃ©el    | Dashboards           |
| **Apache Pinot**  | OLAP streaming     | RequÃªtes low-latency |
| **Elasticsearch** | Search + analytics | Logs & mÃ©triques     |
| **Materialize**   | Streaming SQL      | Vues temps rÃ©el      |


## ğŸ§  Aide mÃ©moire

| Besoin                  | Outils typiques     |
| ----------------------- | ------------------- |
| *Message broker*        | Kafka, Pulsar       |
| *Streaming compute*     | Spark, Flink        |
| *Streaming SQL*         | ksqlDB, Materialize |
| *Orchestration*         | Airflow, Prefect    |
| *Analytique temps rÃ©el* | ClickHouse, Druid   |

```
               +--------------------+
               | Streaming compute  |
               | (traitement)       |
               | Spark / Flink /    |
               | Kafka Streams      |
               +---------+----------+
                         |
            +------------+---------------+
            |       Message brokers      |
            | Kafka / Pulsar / RabbitMQ  |
            | Kinesis / PubSub / Redis   |
            +------------+---------------+
                         |
         +---------------+--------------------+
         |  Stockage / Analytique temps rÃ©el  |
         | ClickHouse / Druid / Elasticsearch |
         +------------------------------------+

```


nouveau vocabulaire Ã  mettre dans la fiche :
* Kafka produit (producer) / consomme (consumer)
* Kafka Ã©crit dans le log dâ€™un topic (append)
* Le consumer lit / relit des messages (read / replay)






Vocabulaire Kafka â€” minimum vital
Producer

ğŸ‘‰ Un producer est une application qui envoie des messages Ã  Kafka.

ex : capteur IoT, simulateur, application backend

rÃ´le : Ã©crire des Ã©vÃ©nements dans un topic

ğŸ‘‰ Kafka produit = des producers Ã©crivent dans Kafka

Consumer

ğŸ‘‰ Un consumer est une application qui lit des messages depuis Kafka.

ex : Spark Structured Streaming

rÃ´le : lire les Ã©vÃ©nements dâ€™un topic

ğŸ‘‰ Kafka consomme = des consumers lisent depuis Kafka

Topic

ğŸ‘‰ Un topic est un canal logique de messages dans Kafka.

comparable Ã  un flux nommÃ©

ex : iot_sensor_data

ğŸ‘‰ Un topic contient des partitions, pas des messages directement.

Log (Kafka log)

ğŸ‘‰ Le log Kafka est une structure de stockage append-only.

les messages sont ajoutÃ©s Ã  la fin

jamais modifiÃ©s ni supprimÃ©s immÃ©diatement

organisÃ©s par partitions

ğŸ‘‰ Quand tu dis :

Kafka Ã©crit dans le log dâ€™un topic

tu dis en rÃ©alitÃ© :

Kafka ajoute des messages Ã  la fin du log de chaque partition du topic.

Append

ğŸ‘‰ Append = ajouter Ã  la fin.

Dans Kafka :

on ne fait que append

pas de update

pas de delete immÃ©diat

Câ€™est ce qui rend Kafka :

simple,

performant,

rejouable.

Read

ğŸ‘‰ Read = lire des messages Ã  partir dâ€™un offset donnÃ©.

un consumer lit sÃ©quentiellement

respecte lâ€™ordre de la partition

peut sâ€™arrÃªter / reprendre

Replay

ğŸ‘‰ Replay = relire des messages dÃ©jÃ  lus.

Possible parce que :

Kafka conserve les messages

les offsets sont stockÃ©s sÃ©parÃ©ment

le consumer peut repartir dâ€™un offset plus ancien

ğŸ‘‰ TrÃ¨s utile pour :

debug,

reprocessing,

nouveaux consommateurs.