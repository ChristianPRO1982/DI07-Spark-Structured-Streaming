# Analyse de flux de donnÃ©es en temps rÃ©el avec Spark Structured Streaming

# Apache Kafka / Apache Spark

## DÃ©finitions

### on-premise

* `on-premise = oÃ¹ Ã§a tourne`
* `on-premise â‰  cloud`

> ğŸ‘‰ on-premise = oÃ¹ Ã§a tourne, et qui gÃ¨re lâ€™infrastructure (hardware, rÃ©seau, sÃ©curitÃ©, dÃ©ploiement).

### Apache Kafka

* `Kafka = log dâ€™Ã©vÃ©nements + dÃ©couplage + relecture`
* `Kafka â‰  queue / trigger`
> une couche de streaming qui collecte/stocke/rejoue des Ã©vÃ©nements, et permet Ã  Spark (ou dâ€™autres) de consommer en continu, de faÃ§on scalable et fiable

### Apache Spark

* `Spark = moteur distribuÃ© batch + streaming`
> Pandas-like API + SQL + exÃ©cution distribuÃ©e + streaming + tolÃ©rance aux pannes

*lâ€™API nâ€™est quâ€™une faÃ§ade dâ€™un moteur distribuÃ©.*

## A retenir

> Spark Structured Streaming fournit une API temps rÃ©el basÃ©e sur un modÃ¨le micro-batch, garantissant cohÃ©rence et tolÃ©rance aux pannes.

> Kafka organise les donnÃ©es par topics dÃ©coupÃ©s en partitions, dans lesquelles les messages sont identifiÃ©s par des offsets, tandis que Spark consomme ces offsets via un consumer group en assurant la reprise grÃ¢ce aux checkpoints.

## Quel problÃ¨me Kafka rÃ©sout que Spark seul ne rÃ©sout pas bien ?

> Kafka apporte une couche de dÃ©couplage et de persistance des flux qui permet Ã  Spark de traiter des donnÃ©es en continu de maniÃ¨re fiable, scalable et tolÃ©rante aux pannes, en absorbant les pics de charge et en permettant la reprise du traitement Ã  partir dâ€™un offset prÃ©cis.

> **Kafka garantit la disponibilitÃ© des Ã©vÃ©nements, Spark garantit la cohÃ©rence du traitement.**

### dÃ©veloppement

> Kafka permet de collecter et stocker des donnÃ©es brutes sous forme dâ€™Ã©vÃ©nements, sans transformation mÃ©tier, en assurant leur persistance via des offsets.

âš ï¸ *Techniquement, Kafka peut faire un minimum (Kafka Streams, SMT).*

> Il dÃ©couple les producteurs (capteurs IoT) des consommateurs (Spark), ce qui permet Ã  Spark de consommer les donnÃ©es Ã  son propre rythme, dâ€™absorber des pics de charge, et de reprendre le traitement Ã  partir dâ€™un offset prÃ©cis en cas dâ€™erreur ou de redÃ©marrage.

**En substance :**
* Kafka absorbe le flux brut
* Spark traite quand il peut, Ã  son rythme
* Et surtout : on peut reprendre

**Exemples :**
* pics IoT â†’ buffer Kafka (`anti-indigestion` ğŸ‘)
* bug applicatif â†’ reprise Ã  offset N (`Ã§a, câ€™est du vÃ©cu`)

**Concepts :**
* Kafka ne fait pas de transformation mÃ©tier, mais il fait bien :
  * de la distribution (partitions),
  * de la rÃ©plication (tolÃ©rance aux pannes).
  * `â†’ Ce nâ€™est pas Spark, mais ce nâ€™est pas â€œjuste du stockageâ€.`
* Spark ne â€œ*cible*â€ pas manuellement les offsets en pratique :
  * il les gÃ¨re automatiquement via les consumer groups + checkpoints,
  * mais ton raisonnement reste correct conceptuellement.

# Workflow

**capteurs â†’ Kafka â†’ Spark**

# Vocabulaire clÃ© (Kafka / Spark Streaming)
## Endpoint
> ğŸ‘‰ Un endpoint est un point dâ€™accÃ¨s rÃ©seau Ã  un service.

Dans le contexte du brief :
* Kafka : host:port dâ€™un broker (localhost:9092)
* Spark : endpoint Kafka pour lire/Ã©crire des messages
* API : URL exposÃ©e par un service

> ğŸ‘‰ **Ã€ retenir :**
Un endpoint ne fait rien tout seul : câ€™est lâ€™adresse oÃ¹ un service est joignable.

## Partition (Kafka)
> ğŸ‘‰ Une partition est une sous-partie ordonnÃ©e dâ€™un topic Kafka.
* Un topic est dÃ©coupÃ© en N partitions
* Chaque partition est :
  * ordonnÃ©e (ordre garanti dans la partition),
  * append-only (on ajoute Ã  la fin),
  * indÃ©pendante des autres partitions

**Pourquoi les partitions existent :**
* parallÃ©lisme (plusieurs consumers en mÃªme temps),
* montÃ©e en charge,
* rÃ©partition des donnÃ©es.

> ğŸ‘‰ **RÃ¨gle clÃ© :**
Lâ€™ordre nâ€™est garanti que dans une partition, jamais entre partitions.

## Offset (Kafka)

> ğŸ‘‰ Un offset est un index numÃ©rique qui identifie la position dâ€™un message dans une partition.

**Ce quâ€™est un offset :**
* un entier croissant (0, 1, 2, 3, â€¦)
* unique par partition
* attribuÃ© automatiquement par Kafka
* liÃ© Ã  un message prÃ©cis

**Ce quâ€™il nâ€™est pas :**
* âŒ pas un timestamp
* âŒ pas global au topic
* âŒ pas une clÃ© mÃ©tier

**Organisation rÃ©elle :**
```
Topic
 â”œâ”€ Partition 0 : offset 0 â†’ 1 â†’ 2 â†’ 3
 â”œâ”€ Partition 1 : offset 0 â†’ 1 â†’ 2
 â””â”€ Partition 2 : offset 0 â†’ 1
```

Chaque partition **a sa propre suite dâ€™offsets**.

**Taille dâ€™un offset :**
* conceptuellement : un nombre (int64)
* physiquement : stockÃ© avec le message dans le log Kafka
* ce nâ€™est pas le message, juste son index

## Consumer Group

> ğŸ‘‰ Un consumer group est un groupe logique de consommateurs qui se partagent les partitions dâ€™un topic.

* 1 partition â†’ 1 consumer max dans un group
* permet :
  * scalabilitÃ©,
  * tolÃ©rance aux pannes,
  * reprise automatique

Spark Structured Streaming **= un consumer group Kafka**.

## Commit dâ€™offset

> ğŸ‘‰ Committer un offset = dire â€œjâ€™ai traitÃ© jusquâ€™iciâ€.

* Kafka stocke les offsets consommÃ©s
* Spark dÃ©cide quand committer :
  * aprÃ¨s Ã©criture rÃ©ussie (Delta, sink, etc.)
  * via checkpoint

> ğŸ‘‰ Si Spark plante avant commit â†’ les messages sont relus.

## Endpoint Kafka vs Topic

Petit piÃ¨ge classique :

* Endpoint = oÃ¹ se connecter (localhost:9092)
* Topic = quoi lire/Ã©crire (iot_sensor_data)

## Mini-schÃ©ma mental (Ã  garder en tÃªte)
```
Capteur
  â†“
Kafka endpoint (broker)
  â†“
Topic
  â†“
Partitions
  â†“
Offsets
  â†“
Spark (consumer group + checkpoint)
```