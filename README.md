# Analyse de flux de donn√©es en temps r√©el avec Spark Structured Streaming

# Apache Kafka / Apache Spark

## D√©finitions

### on-premise

* `on-premise = o√π √ßa tourne`
* `on-premise ‚â† cloud`

> üëâ on-premise = o√π √ßa tourne, et qui g√®re l‚Äôinfrastructure (hardware, r√©seau, s√©curit√©, d√©ploiement).

### Apache Kafka

* `Kafka = log d‚Äô√©v√©nements + d√©couplage + relecture`
* `Kafka ‚â† queue / trigger`
> une couche de streaming qui collecte/stocke/rejoue des √©v√©nements, et permet √† Spark (ou d‚Äôautres) de consommer en continu, de fa√ßon scalable et fiable

### Apache Spark

* `Spark = moteur distribu√© batch + streaming`
> Pandas-like API + SQL + ex√©cution distribu√©e + streaming + tol√©rance aux pannes

*l‚ÄôAPI n‚Äôest qu‚Äôune fa√ßade d‚Äôun moteur distribu√©.*

## A retenir

> Spark Structured Streaming fournit une API temps r√©el bas√©e sur un mod√®le micro-batch, garantissant coh√©rence et tol√©rance aux pannes.

> Kafka organise les donn√©es par topics d√©coup√©s en partitions, dans lesquelles les messages sont identifi√©s par des offsets, tandis que Spark consomme ces offsets via un consumer group en assurant la reprise gr√¢ce aux checkpoints.

## Quel probl√®me Kafka r√©sout que Spark seul ne r√©sout pas bien ?

> Kafka apporte une couche de d√©couplage et de persistance des flux qui permet √† Spark de traiter des donn√©es en continu de mani√®re fiable, scalable et tol√©rante aux pannes, en absorbant les pics de charge et en permettant la reprise du traitement √† partir d‚Äôun offset pr√©cis.

> **Kafka garantit la disponibilit√© des √©v√©nements, Spark garantit la coh√©rence du traitement.**

### d√©veloppement

> Kafka permet de collecter et stocker des donn√©es brutes sous forme d‚Äô√©v√©nements, sans transformation m√©tier, en assurant leur persistance via des offsets.

‚ö†Ô∏è *Techniquement, Kafka peut faire un minimum de transformation (Kafka Streams, SMT).*

> Il d√©couple les producteurs (capteurs IoT) des consommateurs (Spark), ce qui permet √† Spark de consommer les donn√©es √† son propre rythme, d‚Äôabsorber des pics de charge, et de reprendre le traitement √† partir d‚Äôun offset pr√©cis en cas d‚Äôerreur ou de red√©marrage.

**En substance :**
* Kafka absorbe le flux brut
* Spark traite quand il peut, √† son rythme
* Et surtout : on peut reprendre

**Exemples :**
* pics IoT ‚Üí buffer Kafka (`anti-indigestion` üëç)
* bug applicatif ‚Üí reprise √† offset N (`√ßa, c‚Äôest du v√©cu`)

**Concepts :**
* Kafka ne fait pas de transformation m√©tier, mais il fait bien :
  * de la distribution (partitions),
  * de la r√©plication (tol√©rance aux pannes).
  * `‚Üí Ce n‚Äôest pas Spark, mais ce n‚Äôest pas ‚Äújuste du stockage‚Äù.`
* Spark ne ‚Äú*cible*‚Äù pas manuellement les offsets en pratique :
  * il les g√®re automatiquement via les consumer groups + checkpoints,
  * mais ton raisonnement reste correct conceptuellement.

# Workflow

**capteurs ‚Üí Kafka ‚Üí Spark**

# Vocabulaire cl√© (Kafka / Spark Streaming)
## Endpoint
> üëâ Un endpoint est un point d‚Äôacc√®s r√©seau √† un service.

Dans le contexte du brief :
* Kafka : host:port d‚Äôun broker (localhost:9092)
* Spark : endpoint Kafka pour lire/√©crire des messages
* API : URL expos√©e par un service

> üëâ **√Ä retenir :**
Un endpoint ne fait rien tout seul : c‚Äôest l‚Äôadresse o√π un service est joignable.

## Partition (Kafka)
> üëâ Une partition est une sous-partie ordonn√©e d‚Äôun topic Kafka.
* Un topic est d√©coup√© en N partitions
* Chaque partition est :
  * ordonn√©e (ordre garanti dans la partition),
  * append-only (on ajoute √† la fin),
  * ind√©pendante des autres partitions

**Pourquoi les partitions existent :**
* parall√©lisme (plusieurs consumers en m√™me temps),
* mont√©e en charge,
* r√©partition des donn√©es.

> üëâ **R√®gle cl√© :**
L‚Äôordre n‚Äôest garanti que dans une partition, jamais entre partitions.

## Offset (Kafka)

> üëâ Un offset est un index num√©rique qui identifie la position d‚Äôun message dans une partition.

**Ce qu‚Äôest un offset :**
* un entier croissant (0, 1, 2, 3, ‚Ä¶)
* unique par partition
* attribu√© automatiquement par Kafka
* li√© √† un message pr√©cis

**Ce qu‚Äôil n‚Äôest pas :**
* ‚ùå pas un timestamp
* ‚ùå pas global au topic
* ‚ùå pas une cl√© m√©tier

**Organisation r√©elle :**
```
Topic
 ‚îú‚îÄ Partition 0 : offset 0 ‚Üí 1 ‚Üí 2 ‚Üí 3
 ‚îú‚îÄ Partition 1 : offset 0 ‚Üí 1 ‚Üí 2
 ‚îî‚îÄ Partition 2 : offset 0 ‚Üí 1
```

Chaque partition **a sa propre suite d‚Äôoffsets**.

**Taille d‚Äôun offset :**
* conceptuellement : un nombre (int64)
* physiquement : stock√© avec le message dans le log Kafka
* ce n‚Äôest pas le message, juste son index

## Consumer Group

> üëâ Un consumer group est un groupe logique de consommateurs qui se partagent les partitions d‚Äôun topic.

* 1 partition ‚Üí 1 consumer max dans un group
* permet :
  * scalabilit√©,
  * tol√©rance aux pannes,
  * reprise automatique

Spark Structured Streaming **= un consumer group Kafka**.

## Commit d‚Äôoffset

> üëâ Committer un offset = dire ‚Äúj‚Äôai trait√© jusqu‚Äôici‚Äù.

* Kafka stocke les offsets consomm√©s
* Spark d√©cide quand committer :
  * apr√®s √©criture r√©ussie (Delta, sink, etc.)
  * via checkpoint

> üëâ Si Spark plante avant commit ‚Üí les messages sont relus.

## Endpoint Kafka vs Topic

Petit pi√®ge classique :

* Endpoint = o√π se connecter (localhost:9092)
* Topic = quoi lire/√©crire (iot_sensor_data)

## Mini-sch√©ma mental (√† garder en t√™te)
```
Capteur
  ‚Üì
Kafka endpoint (broker)
  ‚Üì
Topic
  ‚Üì
Partitions
  ‚Üì
Offsets
  ‚Üì
Spark (consumer group + checkpoint)
```

# Concurrence

## üîÑ Outils de streaming / traitement de flux
> (Concurrents de Spark Structured Streaming)

| Outil                                 | Type                  | Points forts                      | Diff√©rence cl√© avec Spark |
| ------------------------------------- | --------------------- | --------------------------------- | ------------------------- |
| **Apache Spark Structured Streaming** | Micro-batch streaming | Robuste, SQL, batch + streaming   | Latence > Flink           |
| **Apache Flink**                      | Streaming natif       | Vrai streaming, event-time avanc√© | Plus complexe √† op√©rer    |
| **Apache Beam**                       | SDK unifi√©            | Portabilit√© multi-engines         | Pas un moteur             |
| **Kafka Streams**                     | Lib Java              | L√©ger, int√©gr√© Kafka              | Pas distribu√© seul        |
| **ksqlDB**                            | Streaming SQL         | SQL temps r√©el                    | Cas d‚Äôusage limit√©s       |
| **Apache Storm**                      | Streaming bas niveau  | Tr√®s faible latence               | Ancien, verbeux           |
| **Serverless streaming**              | Event-driven          | Scalabilit√© auto                  | D√©pendance cloud          |

## üì® Message brokers / Pub-Sub
> (Concurrents de Kafka)

| Outil                | Type              | Points forts                 | Diff√©rence cl√© avec Kafka    |
| -------------------- | ----------------- | ---------------------------- | ---------------------------- |
| **Apache Kafka**     | Log distribu√©     | Replay, d√©bit massif         | Complexit√© infra             |
| **Apache Pulsar**    | Pub-Sub distribu√© | Multi-tenant, storage s√©par√© | Moins r√©pandu                |
| **RabbitMQ**         | Message Queue     | Routing avanc√©               | Pas con√ßu pour replay massif |
| **AWS Kinesis**      | Streaming manag√©  | Int√©gr√© AWS                  | Cloud only                   |
| **Google Pub/Sub**   | Pub-Sub manag√©    | Scalabilit√© auto             | Pas d‚Äôon-prem                |
| **Azure Event Hubs** | Event streaming   | √âquivalent Kafka Azure       | Azure only                   |
| **Redis Streams**    | Streams m√©moire   | Faible latence               | R√©tention limit√©e            |

## üì¶ Ingestion / orchestration / pipelines
> (Compl√©ment au streaming)

| Outil              | R√¥le                  | Usage principal  |
| ------------------ | --------------------- | ---------------- |
| **Apache NiFi**    | Ingestion visuelle    | Routage de flux  |
| **Apache Airflow** | Orchestration batch   | ETL planifi√©s    |
| **Prefect**        | Orchestration moderne | Pipelines Python |
| **Dagster**        | Data orchestration    | Data-centric     |
| **dbt**            | Transformation SQL    | ELT analytique   |

## üìä Analytique temps r√©el / stockage
> (Consommateurs de flux)

| Outil             | Type               | Usage                |
| ----------------- | ------------------ | -------------------- |
| **ClickHouse**    | OLAP               | Analytique rapide    |
| **Apache Druid**  | OLAP temps r√©el    | Dashboards           |
| **Apache Pinot**  | OLAP streaming     | Requ√™tes low-latency |
| **Elasticsearch** | Search + analytics | Logs & m√©triques     |
| **Materialize**   | Streaming SQL      | Vues temps r√©el      |


## üß† Aide m√©moire

| Besoin                  | Outils typiques     |
| ----------------------- | ------------------- |
| *Message broker*        | Kafka, Pulsar       |
| *Streaming compute*     | Spark, Flink        |
| *Streaming SQL*         | ksqlDB, Materialize |
| *Orchestration*         | Airflow, Prefect    |
| *Analytique temps r√©el* | ClickHouse, Druid   |

```
               +--------------------+
               | Streaming compute  |
               | (traitement)       |
               | Spark / Flink /    |
               | Kafka Streams      |
               +---------+----------+
                         |
            +------------+---------------+
            |       Message brokers      |
            | Kafka / Pulsar / RabbitMQ  |
            | Kinesis / PubSub / Redis   |
            +------------+---------------+
                         |
         +---------------+--------------------+
         |  Stockage / Analytique temps r√©el  |
         | ClickHouse / Druid / Elasticsearch |
         +------------------------------------+

```