# Analyse de flux de donn√©es en temps r√©el avec Spark Structured Streaming

<details>
  <summary><strong>üìå Sommaire</strong></summary>

- [Apache Kafka / Apache Spark](#apache-kafka--apache-spark)
  - [D√©finitions](#d√©finitions)
    - [on-premise](#on-premise)
    - [Apache Kafka](#apache-kafka)
    - [Apache Spark](#apache-spark)
  - [√Ä retenir](#a-retenir)
  - [Quel probl√®me Kafka r√©sout que Spark seul ne r√©sout pas bien ?](#quel-probl√®me-kafka-r√©sout-que-spark-seul-ne-r√©sout-pas-bien-)
    - [D√©veloppement](#d√©veloppement)
- [Workflow](#workflow)
- [Vocabulaire cl√© (Kafka / Spark Streaming)](#vocabulaire-cl√©-kafka--spark-streaming)
  - [Endpoint](#endpoint)
  - [Partition (Kafka)](#partition-kafka)
  - [Offset (Kafka)](#offset-kafka)
  - [Producer](#producer)
  - [Consumer](#consumer)
  - [Topic](#topic)
  - [Log (Kafka log)](#log-kafka-log)
  - [Append](#append)
  - [Read](#read)
  - [Replay](#replay)
  - [Consumer Group](#consumer-group)
  - [Commit d‚Äôoffset](#commit-doffset)
  - [Endpoint Kafka vs Topic](#endpoint-kafka-vs-topic)
  - [Mini-sch√©ma mental (√† garder en t√™te)](#mini-sch√©ma-mental-√†-garder-en-t√™te)
- [Concurrence](#concurrence)
  - [Outils de streaming / traitement de flux](#-outils-de-streaming--traitement-de-flux)
  - [Message brokers / Pub-Sub](#-message-brokers--pub-sub)
  - [Ingestion / orchestration / pipelines](#-ingestion--orchestration--pipelines)
  - [Analytique temps r√©el / stockage](#-analytique-temps-r√©el--stockage)
  - [Aide m√©moire](#-aide-m√©moire)

</details>

# Apache Kafka / Apache Spark

## D√©finitions

### on-premise

* `on-premise = o√π √ßa tourne`
* `on-premise ‚â† cloud`

> üëâ on-premise = o√π √ßa tourne, et qui g√®re l‚Äôinfrastructure (hardware, r√©seau, s√©curit√©, d√©ploiement).

[Top](#)

### Apache Kafka

* `Kafka = log d‚Äô√©v√©nements + d√©couplage + relecture`
* `Kafka ‚â† queue / trigger`
> une couche de streaming qui collecte/stocke/rejoue des √©v√©nements, et permet √† Spark (ou d‚Äôautres) de consommer en continu, de fa√ßon scalable et fiable

[Top](#)

### Apache Spark

* `Spark = moteur distribu√© batch + streaming`
> Pandas-like API + SQL + ex√©cution distribu√©e + streaming + tol√©rance aux pannes

*l‚ÄôAPI n‚Äôest qu‚Äôune fa√ßade d‚Äôun moteur distribu√©.*

[Top](#)

## A retenir

> Spark Structured Streaming fournit une API temps r√©el bas√©e sur un mod√®le micro-batch, garantissant coh√©rence et tol√©rance aux pannes.

> Kafka organise les donn√©es par topics d√©coup√©s en partitions, dans lesquelles les messages sont identifi√©s par des offsets, tandis que Spark consomme ces offsets via un consumer group en assurant la reprise gr√¢ce aux checkpoints.

Avec le vocabulaire :
* Kafka produit (producer) / consomme (consumer)
* Kafka √©crit dans le log d‚Äôun topic (append)
* Le consumer lit / relit des messages (read / replay)

ce que l'on peut faire dans bronze :
| Usage                   | Lecture Bronze |
| ----------------------- | -------------- |
| Pipeline temps r√©el     | ‚úÖ stream       |
| Reprocessing / backfill | ‚úÖ batch        |
| Debug / audit           | ‚úÖ batch        |
| Contr√¥les qualit√©       | ‚úÖ batch        |
| Exploration             | ‚úÖ batch        |

[Top](#)

## Quel probl√®me Kafka r√©sout que Spark seul ne r√©sout pas bien ?

> Kafka apporte une couche de d√©couplage et de persistance des flux qui permet √† Spark de traiter des donn√©es en continu de mani√®re fiable, scalable et tol√©rante aux pannes, en absorbant les pics de charge et en permettant la reprise du traitement √† partir d‚Äôun offset pr√©cis.

> **Kafka garantit la disponibilit√© des √©v√©nements, Spark garantit la coh√©rence du traitement.**

[Top](#)

### d√©veloppement

> Kafka permet de collecter et stocker des donn√©es brutes sous forme d‚Äô√©v√©nements, sans transformation m√©tier, en assurant leur persistance via des offsets.

‚ö†Ô∏è *Techniquement, Kafka peut faire un minimum de transformation (Kafka Streams, SMT).*

> Il d√©couple les producteurs (capteurs IoT) des consommateurs (Spark), ce qui permet √† Spark de consommer les donn√©es √† son propre rythme, d‚Äôabsorber des pics de charge, et de reprendre le traitement √† partir d‚Äôun offset pr√©cis en cas d‚Äôerreur ou de red√©marrage.

**En substance :**
* Kafka absorbe le flux brut
* Spark traite quand il peut, √† son rythme
* Et surtout : on peut reprendre

**Exemples :**
* pics IoT ‚Üí buffer Kafka (`anti-indigestion` üëç)
* bug applicatif ‚Üí reprise √† offset N (`√ßa, c‚Äôest du v√©cu`)

**Concepts :**
* Kafka ne fait pas de transformation m√©tier, mais il fait bien :
  * de la distribution (partitions),
  * de la r√©plication (tol√©rance aux pannes).
  * `‚Üí Ce n‚Äôest pas Spark, mais ce n‚Äôest pas ‚Äújuste du stockage‚Äù.`
* Spark ne ‚Äú*cible*‚Äù pas manuellement les offsets en pratique :
  * il les g√®re automatiquement via les consumer groups + checkpoints,
  * mais ton raisonnement reste correct conceptuellement.

[Top](#)

# Workflow

**capteurs ‚Üí Kafka ‚Üí Spark**

# Vocabulaire cl√© (Kafka / Spark Streaming)

[Top](#)

## Endpoint
> üëâ Un endpoint est un point d‚Äôacc√®s r√©seau √† un service.

Dans le contexte du brief :
* Kafka : host:port d‚Äôun broker (localhost:9092)
* Spark : endpoint Kafka pour lire/√©crire des messages
* API : URL expos√©e par un service

> üëâ **√Ä retenir :**
Un endpoint ne fait rien tout seul : c‚Äôest l‚Äôadresse o√π un service est joignable.

[Top](#)

## Partition (Kafka)
> üëâ Une partition est une sous-partie ordonn√©e d‚Äôun topic Kafka.
* Un topic est d√©coup√© en N partitions
* Chaque partition est :
  * ordonn√©e (ordre garanti dans la partition),
  * append-only (on ajoute √† la fin),
  * ind√©pendante des autres partitions

**Pourquoi les partitions existent :**
* parall√©lisme (plusieurs consumers en m√™me temps),
* mont√©e en charge,
* r√©partition des donn√©es.

> üëâ **R√®gle cl√© :**
L‚Äôordre n‚Äôest garanti que dans une partition, jamais entre partitions.

[Top](#)

## Offset (Kafka)

> üëâ Un offset est un index num√©rique qui identifie la position d‚Äôun message dans une partition.

**Ce qu‚Äôest un offset :**
* un entier croissant (0, 1, 2, 3, ‚Ä¶)
* unique par partition
* attribu√© automatiquement par Kafka
* li√© √† un message pr√©cis

**Ce qu‚Äôil n‚Äôest pas :**
* ‚ùå pas un timestamp
* ‚ùå pas global au topic
* ‚ùå pas une cl√© m√©tier

**Organisation r√©elle :**
```
Topic
 ‚îú‚îÄ Partition 0 : offset 0 ‚Üí 1 ‚Üí 2 ‚Üí 3
 ‚îú‚îÄ Partition 1 : offset 0 ‚Üí 1 ‚Üí 2
 ‚îî‚îÄ Partition 2 : offset 0 ‚Üí 1
```

Chaque partition **a sa propre suite d‚Äôoffsets**.

**Taille d‚Äôun offset :**
* conceptuellement : un nombre (int64)
* physiquement : stock√© avec le message dans le log Kafka
* ce n‚Äôest pas le message, juste son index

[Top](#)

## Producer

> üëâ Un producer est une application qui envoie des messages √† Kafka.

**ex :** capteur IoT, simulateur, application backend

**r√¥le :** √©crire des √©v√©nements dans un topic

> üëâ Kafka produit = des producers √©crivent dans Kafka

[Top](#)

## Consumer

> üëâ Un consumer est une application qui lit des messages depuis Kafka.

**ex :** Spark Structured Streaming

**r√¥le :** lire les √©v√©nements d‚Äôun topic

> üëâ Kafka consomme = des consumers lisent depuis Kafka

[Top](#)

## Topic

> üëâ Un topic est un canal logique de messages dans Kafka.

comparable √† un flux nomm√©

**ex :** iot_sensor_data

> üëâ Un topic contient des partitions, pas des messages directement.

[Top](#)

## Log (Kafka log)

> üëâ Le log Kafka est une structure de stockage append-only.

Les messages sont ajout√©s √† la fin. Jamais modifi√©s ni supprim√©s imm√©diatement. Organis√©s par partitions

> üëâ Quand tu dis :

Kafka √©crit dans le log d‚Äôun topic. En r√©alit√© : Kafka ajoute des messages √† la fin du log de chaque partition du topic.

[Top](#)

## Append

> üëâ Append = ajouter √† la fin.

Dans Kafka :
* on ne fait que append
* pas de update
* pas de delete imm√©diat

C‚Äôest ce qui rend Kafka :
* simple,
* performant,
* rejouable.

[Top](#)

## Read

> üëâ Read = lire des messages √† partir d‚Äôun offset donn√©.

Un consumer lit s√©quentiellement. Respecte l‚Äôordre de la partition. Peut s‚Äôarr√™ter / reprendre.

[Top](#)

## Replay

> üëâ Replay = relire des messages d√©j√† lus.

Possible parce que :
* Kafka conserve les messages
* les offsets sont stock√©s s√©par√©ment
* le consumer peut repartir d‚Äôun offset plus ancien

[Top](#)

## Consumer Group

> üëâ Un consumer group est un groupe logique de consommateurs qui se partagent les partitions d‚Äôun topic.

* 1 partition ‚Üí 1 consumer max dans un group
* permet :
  * scalabilit√©,
  * tol√©rance aux pannes,
  * reprise automatique

Spark Structured Streaming **= un consumer group Kafka**.

[Top](#)

## Commit d‚Äôoffset

> üëâ Committer un offset = dire ‚Äúj‚Äôai trait√© jusqu‚Äôici‚Äù.

* Kafka stocke les offsets consomm√©s
* Spark d√©cide quand committer :
  * apr√®s √©criture r√©ussie (Delta, sink, etc.)
  * via checkpoint

> üëâ Si Spark plante avant commit ‚Üí les messages sont relus.

[Top](#)

## Endpoint Kafka vs Topic

Petit pi√®ge classique :

* Endpoint = o√π se connecter (localhost:9092)
* Topic = quoi lire/√©crire (iot_sensor_data)

[Top](#)

# Mini-sch√©ma mental (√† garder en t√™te)
```
Capteur
  ‚Üì
Kafka endpoint (broker)
  ‚Üì
Topic
  ‚Üì
Partitions
  ‚Üì
Offsets
  ‚Üì
Spark (consumer group + checkpoint)
```

[Top](#)

# Concurrence

## üîÑ Outils de streaming / traitement de flux
> (Concurrents de Spark Structured Streaming)

| Outil                                 | Type                  | Points forts                      | Diff√©rence cl√© avec Spark |
| ------------------------------------- | --------------------- | --------------------------------- | ------------------------- |
| **Apache Spark Structured Streaming** | Micro-batch streaming | Robuste, SQL, batch + streaming   | Latence > Flink           |
| **Apache Flink**                      | Streaming natif       | Vrai streaming, event-time avanc√© | Plus complexe √† op√©rer    |
| **Apache Beam**                       | SDK unifi√©            | Portabilit√© multi-engines         | Pas un moteur             |
| **Kafka Streams**                     | Lib Java              | L√©ger, int√©gr√© Kafka              | Pas distribu√© seul        |
| **ksqlDB**                            | Streaming SQL         | SQL temps r√©el                    | Cas d‚Äôusage limit√©s       |
| **Apache Storm**                      | Streaming bas niveau  | Tr√®s faible latence               | Ancien, verbeux           |
| **Serverless streaming**              | Event-driven          | Scalabilit√© auto                  | D√©pendance cloud          |

[Top](#)

## üì® Message brokers / Pub-Sub
> (Concurrents de Kafka)

| Outil                | Type              | Points forts                 | Diff√©rence cl√© avec Kafka    |
| -------------------- | ----------------- | ---------------------------- | ---------------------------- |
| **Apache Kafka**     | Log distribu√©     | Replay, d√©bit massif         | Complexit√© infra             |
| **Apache Pulsar**    | Pub-Sub distribu√© | Multi-tenant, storage s√©par√© | Moins r√©pandu                |
| **RabbitMQ**         | Message Queue     | Routing avanc√©               | Pas con√ßu pour replay massif |
| **AWS Kinesis**      | Streaming manag√©  | Int√©gr√© AWS                  | Cloud only                   |
| **Google Pub/Sub**   | Pub-Sub manag√©    | Scalabilit√© auto             | Pas d‚Äôon-prem                |
| **Azure Event Hubs** | Event streaming   | √âquivalent Kafka Azure       | Azure only                   |
| **Redis Streams**    | Streams m√©moire   | Faible latence               | R√©tention limit√©e            |

[Top](#)

## üì¶ Ingestion / orchestration / pipelines
> (Compl√©ment au streaming)

| Outil              | R√¥le                  | Usage principal  |
| ------------------ | --------------------- | ---------------- |
| **Apache NiFi**    | Ingestion visuelle    | Routage de flux  |
| **Apache Airflow** | Orchestration batch   | ETL planifi√©s    |
| **Prefect**        | Orchestration moderne | Pipelines Python |
| **Dagster**        | Data orchestration    | Data-centric     |
| **dbt**            | Transformation SQL    | ELT analytique   |

[Top](#)

## üìä Analytique temps r√©el / stockage
> (Consommateurs de flux)

| Outil             | Type               | Usage                |
| ----------------- | ------------------ | -------------------- |
| **ClickHouse**    | OLAP               | Analytique rapide    |
| **Apache Druid**  | OLAP temps r√©el    | Dashboards           |
| **Apache Pinot**  | OLAP streaming     | Requ√™tes low-latency |
| **Elasticsearch** | Search + analytics | Logs & m√©triques     |
| **Materialize**   | Streaming SQL      | Vues temps r√©el      |

[Top](#)


## üß† Aide m√©moire

| Besoin                  | Outils typiques     |
| ----------------------- | ------------------- |
| *Message broker*        | Kafka, Pulsar       |
| *Streaming compute*     | Spark, Flink        |
| *Streaming SQL*         | ksqlDB, Materialize |
| *Orchestration*         | Airflow, Prefect    |
| *Analytique temps r√©el* | ClickHouse, Druid   |

[Top](#)

```
               +--------------------+
               | Streaming compute  |
               | (traitement)       |
               | Spark / Flink /    |
               | Kafka Streams      |
               +---------+----------+
                         |
            +------------+---------------+
            |       Message brokers      |
            | Kafka / Pulsar / RabbitMQ  |
            | Kinesis / PubSub / Redis   |
            +------------+---------------+
                         |
         +---------------+--------------------+
         |  Stockage / Analytique temps r√©el  |
         | ClickHouse / Druid / Elasticsearch |
         +------------------------------------+

```

[Top](#)
